---
title: 'Propositions: Part 3'
date: 2025-08-27
permalink: /posts/2025/08/blog-post-5/
tags:
  - lean
  - logic
  - propositions
  - negation
  - contradiction
  - implication
  - tautology
---

Recall that a proposition can be True or False. If `p` is a proposition that evaluates to True, we often denote `¬p` to mean the proposition that evaluates to False. Alternatively, if `p` evaluates to False, then `¬p` evaluates to True. In general, when we state a proposition `p`, we assume it evaluates to True.

The negation operator (symbolized by `¬`) is a unary operator. It acts on a single proposition. We will show how the negation operator works in compound propositions. First, let's look at some examples:

| p | ¬p |
|---|---|
| The integer `m` is odd | The integer `m` is even |
| `x` is greater than zero | `x` is less than *or* equal to zero |
| `t` is in the set `S` | `t` is not a member of the set `S` |

## Working with Double Negation

In classical logic, `¬¬p` is equivalent to `p`. Here's a simple example:

```lean
example (p : Prop) (h : p) : ¬¬p := by
  push_neg
  exact h
```

The `push_neg` tactic simplifies negations in a goal. You can also use `push_neg at h` to simplify negations in a hypothesis labeled `h`.

## Contradiction and the Law of Excluded Middle

A fundamental principle in classical logic is the **Law of Excluded Middle**: every proposition is either true or its negation is true.

```lean
-- Law of Excluded Middle
example (p : Prop) : p ∨ ¬p := by
  by_cases h : p
  · -- Case: p is true
    left
    exact h
  · -- Case: p is false (¬p) 
    right
    exact h
```

This demonstrates an important proof technique: the `by_cases` tactic splits on whether a proposition is true or false, allowing us to handle all possibilities. We saw this key tactic in our previous chapter.

## Understanding Contradiction

When we have both a proposition and its negation as hypotheses, we have a **contradiction**. From a contradiction, we can prove anything (even a false statement):

```lean
-- If we assume both p and ¬p, we can derive p ∧ ¬p
example (p : Prop) (h1 : p) (h2 : ¬p) : p ∧ ¬p := by
  constructor
  · exact h1
  · exact h2
```
Lean will not complain and we will have seemingly proved a contradictory statement. Surely, `p` and `¬p` cannot both be true. Just because the Lean is happy with the proof does not necessarily mean you have proven something. Always check that whatever you're trying to prove is sound.

Another way to prove the same result is to use the `contradiction` tactic.
```lean
-- The contradiction tactic recognizes contradictory hypotheses automatically
example (p : Prop) (h1 : p) (h2 : ¬p) : p ∧ ¬p := by
  contradiction
```

The `contradiction` tactic is powerful — it can close any goal when contradictory hypotheses are present. This embodies the principle of *ex contradictione quodlibet* ("from contradiction, anything follows").

## Proof by Contradiction

Sometimes the most natural way to prove something is to assume it's false and derive a contradiction. The `by_contra` tactic enables this proof strategy:

```lean
-- Proof by contradiction: assume the goal is false, then derive contradiction
example (p : Prop) : ¬(p ∧ ¬p) := by
  by_contra h          -- Suppose h : p ∧ ¬p
  have h1 := h.left    -- h1 : p
  have h2 := h.right   -- h2 : ¬p  
  contradiction        -- h1 and h2 contradict each other
```

The `by_contra` tactic:
1. Assumes the negation of the goal as a new hypothesis
2. Changes the goal to `False`
3. Requires you to derive a contradiction from the new assumption

## Understanding Implication

Now that we understand negation, we can explore **implication** — one of the most fundamental concepts in mathematical reasoning. An implication `p → q` means "if p then q" or "p implies q.". We refer to `p` as the antecedent and `q` as the consequent in an implication `p → q`.

Surprisingly, implication can be understood in terms of disjunction and negation. The statement `p → q` is logically equivalent to `¬p ∨ q`. If you think about it: "if p then q" is false only when p is true but q is false. In all other cases — when p is false (making `¬p` true) or when q is true — the implication holds ([vacuously](https://en.wikipedia.org/wiki/Vacuous_truth)).

Here's the key insight: `p → q` means "either p is false, or q is true (or both)."

### The `intro` Tactic: Building Implications

The `intro` tactic is fundamental for working with implications. When you have a goal of the form `p → q`, the `intro` tactic acts on the goal allowing you to:
1. Assume `p` as a hypothesis
2. Change the goal to prove `q`

This directly corresponds to the logical reasoning: "To prove 'if p then q', assume p and then prove q."

Let's start with a simple example:

```lean
example (p : Prop) : p → p := by
  -- ⊢ p → p
  intro h -- assume p as hypothesis h
  -- h : p
  -- ⊢ p
  exact h
```
The goal follows from our assumption using `intro`.

In the very first example of this chapter, we looked at double negation. We can express that example differently using implication:

```lean
example (p : Prop) : p → ¬¬p := by
  -- ⊢ p → ¬¬p
  push_neg
  -- ⊢ p → p
  intro h -- assume p as hypothesis h
  -- h : p
  -- ⊢ p
  exact h
```
The `push_neg` tactic and `intro` tactic both work on the goal by default. They can be used interchangeably. Try finishing this example:
```lean
example (p : Prop) : p → ¬¬p := by
  intro h
  sorry
```
You can also use `intro` multiple times for nested implications. Remember that `p → q → r` is the same as `p → (q → r)` :

```lean
-- Multiple implications can be introduced one by one
example (p q r : Prop) : p → q → r → p := by
  intro hp   -- Assume p, goal becomes: q → r → p
  intro hq   -- Assume q, goal becomes: r → p  
  intro hr   -- Assume r, goal becomes: p
  exact hp   -- We still have p from the first assumption
```

Or more concisely:

```lean
-- Multiple implications can be introduced at once
example (p q r : Prop) : p → q → r → p := by
  intro hp hq hr  -- Introduce all three hypotheses at once
  exact hp        -- Return the first one
```

This demonstrates an important principle: once you have a hypothesis, you can use it anywhere in the rest of the proof, even after introducing more hypotheses.

### The `apply` Tactic: Using Implications

While `intro` helps us *prove* implications, `apply` helps us *use* implications we already have. The `apply` tactic implements **backward reasoning**: instead of building up from assumptions, we work backward from the goal.

When you have a hypothesis `h : p → q` and a goal `⊢ q`, you can use `apply h` to change the goal to `⊢ p`. This corresponds to the logical reasoning: "To prove q, it suffices to prove p (since we know p implies q)."

Let's see this in action:

```lean
-- Using an implication we already have
example (p q : Prop) (h : p → q) (hp : p) : q := by
  apply h    -- Since h : p → q and goal is q, new goal becomes p
  exact hp   -- We can prove p using hp
```

The `apply` tactic can also work with more complex implications:

```lean
-- Applying implications with multiple premises
example (p q r : Prop) (h : p → q → r) (hp : p) (hq : q) : r := by
  -- Goal splits into two: prove Q, then prove P (like apply is done twice)
  apply h
  · -- ⊢ p
    exact hp  
  · -- ⊢ q
    exact hq
```

Notice how `apply h` with `h : p → q → r` and goal `r` creates two subgoals: prove `p` and prove `q`. This is because `p → q → r` means `p → (q → r)`, so to use this implication, we need both premises. 

How would the proof change if the precedence was different?
```lean
example (p q r : Prop) (h : (p → q) → r) (hq : q) : r := by
  -- ⊢ r
  apply h
  -- ⊢ p → q
  sorry
```

### Combining `intro` and `apply`

Often you'll use both tactics together. Here's a common pattern:

```lean
-- A theorem that builds and uses implications
example (p q r : Prop) : (p → q) → (q → r) → (p → r) := by
  intro h1    -- Suppose h1 : p → q
  -- ⊢ ( q → r ) → p → r
  intro h2    -- Suppose h2 : q → r
  -- ⊢ p → r  
  intro hp    -- Suppose hp : p (to prove p → r)
  -- ⊢ r
  apply h2    -- To prove r, prove q (since q → r)
  -- ⊢ q
  apply h1    -- To prove q, prove p (since p → q)
  -- ⊢ p
  exact hp    -- We have p from our assumption
```
This proof demonstrates the transitivity of implication: if `p → q` and `q → r`, then `p → r`.

### Alternative: Treating Implications as Functions

There's another way to think about implications in Lean: as functions. An implication `p → q` can be applied like a function to an argument of type `p` to produce a result of type `q`. In Lean, if you have a function `f` and argument `x`, then `f x` is syntactically equivalent to `f(x)` or `f` applied to `x`.

```lean
-- Using implications as functions
example (p q : Prop) (h : p → q) (hp : p) : q := by
  exact h hp  -- use function h on argument hp

-- This also works with the "have" tactic for intermediate results
example (p q r : Prop) (h1 : p → q) (h2 : q → r) (hp : p) : r := by
  have hq := h1 hp  -- h1 hp gives q
  have hr := h2 hq  -- h2 hq gives r
  exact hr
```

### Negation and Implications

Negation can also be expressed as an implication. If you have a statement `¬p`, then this is also equivalent to the statement `p → False`.

As a result, if you use the `intro` tactic when the goal is `¬p`, then you get an additional hypothesis `p` and the goal changes to False. 

Let's look at an example. Normally, we'd just use `exact` but we emphasize the implication definition of negation:
```lean
example (p : Prop) (h : ¬p) : ¬p := by
  intro hp
  -- h : ¬p
  -- hp : p
  -- ⊢ False
  contradiction
```
Intuitively, this is like the `by_contra` tactic we looked at earlier. In fact, using it is similar in this context:
```lean
example (p : Prop) (h : ¬p) : ¬p := by
  by_contra hp
  -- h: ¬p
  -- hp : p
  -- ⊢ False
  contradiction
```

Similarly, if you have a goal that is False and a hypothesis `hnp : p → False`, then using the `apply hp` tactic changes the goal to `p`:
```lean
example (p : Prop) (hp : p) (hnp : p → False) : False := by
  apply hnp
  -- hp : p
  -- hnp : p → False
  -- ⊢ p
  exact hp
```

## Putting it all together
Here are more examples that combine these concepts:

```lean
-- negation, implication forward, and implication backward
example (p q : Prop) (h : p → q) : ¬q → ¬p := by
  intro nq    -- Suppose nq : ¬q (q → False)
  intro hp    -- Suppose hp : p and derive contradiction
  -- ⊢ False
  apply nq    -- To get contradiction, apply ¬q (q → False)
  -- ⊢ q
  exact h hp  -- Prove q using h and hp
```
Many mathematical statements are transitive (like a chain). One implication's conclusion is evidence for another implication. Remember that the precedence is associated to the right (`p → q → r` means `p → (q → r)`).

```lean
example (p q r s : Prop) (h : p → q → r → s) (hp : p) : q → r → s := by
  intro hq hr  -- Suppose hq : q and hr : r
  -- ⊢ s
  apply h      -- Apply h, which needs p, q, and r
  · exact hp   -- Prove p
  · exact hq   -- Prove q
  · exact hr   -- Prove r
```
To summarize, the `intro` tactic implements forward reasoning (from assumptions to conclusion) and the `apply` tactic implements backward reasoning (from conclusion to assumptions).

## Contrapositive

Now that we have a solid understanding of implications, we can look at the **contrapositive** — another powerful proof technique. The contrapositive of `p → q` is `¬q → ¬p`, and these statements are logically equivalent.

We proved this first part in the last section:
```lean
-- Proving the contrapositive manually
example (p q : Prop) (h : p → q) : ¬q → ¬p := by
  sorry
```

Let's try a slightly different approach:
```lean
-- Alternative proof using contradiction
example (p q : Prop) (h : p → q) : ¬q → ¬p := by
  intro nq    -- Assume ¬q  
  intro hp    -- Assume p
  have hq := h hp    -- Derive q from p → q and p
  contradiction      -- nq and hq contradict each other
```

Lean also provides a `contrapose` tactic for this common pattern:
```lean
example (p q : Prop) (h : p → q) : ¬q → ¬p := by
  contrapose
  -- ⊢ ¬¬p → ¬¬q
  push_neg
  -- ⊢ p → q
  exact h
```

## Negation with Conjunctions and Disjunctions

One of the most important relationships in logic involves how negation interacts with conjunctions and disjunctions. These are known as **De Morgan's Laws**:

- `¬(p ∧ q)` is equivalent to `¬p ∨ ¬q` — "Not (p and q)" is equivalent to "Not p or not q"
- `¬(p ∨ q)` is equivalent to `¬p ∧ ¬q` — "Not (p or q)" is equivalent to "Not p and not q"

Intuitively, we distribute the negation and flip the conjunction and disjunction symbol.

The negation operator binds more strongly than conjunction (`∧`) or disjunction (`∨`), so `¬p ∧ q` means `(¬p) ∧ q`.

Let's prove the first De Morgan's law step by step:

```lean
-- De Morgan's Law: ¬(p ∧ q) → (¬p ∨ ¬q)
example (p q : Prop) : ¬(p ∧ q) → (¬p ∨ ¬q) := by
  intro h          -- Assume ¬(p ∧ q)
  by_cases hp : p  -- Consider whether p is true or false
  · -- Case: p is true
    right          -- Show ¬q (right side of disjunction)
    intro hq       -- To prove ¬q, assume q and derive contradiction
    apply h        -- Apply h : ¬(p ∧ q) to goal p ∧ q
    constructor
    · exact hp
    · exact hq
  · -- Case: p is false (¬p)
    left           -- Show ¬p (left side of disjunction)  
    exact hp

-- De Morgan's Law: ¬(p ∨ q) → (¬p ∧ ¬q)
example (p q : Prop) : ¬(p ∨ q) → (¬p ∧ ¬q) := by
  intro h          -- Assume ¬(p ∨ q)
  constructor
  · -- Show ¬p
    intro hp       -- Assume p, derive contradiction
    apply h        -- Apply h to goal p ∨ q
    left           -- Show p
    exact hp
  · -- Show ¬q  
    intro hq       -- Assume q, derive contradiction
    apply h        -- Apply h to goal p ∨ q
    right          -- Show q
    exact hq
```

## Tautological Equivalences

We've proven equivalences between logical statements in this chapter and previous chapters. Many logical relationships are **tautological equivalences** — they're true purely by virtue of logical structure, regardless of the specific propositions involved. We can use the **if and only if** (`↔`) operator to express these equivalences. The **if and only if** operator (`↔`) expresses logical equivalence — the statements on both sides have the same truth value in all cases.

Let's look at some examples:

```lean
-- logical equivalence of negation and contradiction

-- The constructor tactic is used to prove these kinds of goals
-- It considers two cases:
-- 1. The forward direction: P → Q
-- 2. The converse: Q → P
example (p : Prop) : ¬p ↔ p → False := by
  constructor
  · -- case mp
    -- p : Prop
    -- ⊢ ¬p → p → False
    intro np
    -- np : ¬p
    -- ⊢ p → False
    intro p'
    -- np : ¬p
    -- p' : p
    -- ⊢ False
    contradiction
  
  · -- case mpr
    -- p : Prop
    -- ⊢ (p → False) → ¬p
    contrapose
    -- ⊢ ¬¬p → ¬(p → False)
    push_neg
    -- ⊢ p → p ∧ ¬False
    intro p'
    -- p' : p
    -- ⊢ p ∧ ¬False
    constructor
    · -- ⊢ p
      exact p'
    · -- ⊢ ¬False
      trivial
```

There may be times you have an `↔` statement as a hypothesis `h`. If your hypothesis is `p ↔ q`, `h.mp` gives `p → q` (the forward direction) and `h.mpr` gives the converse (reverse) `q → p`.

```lean
-- logical equivalence of contrapositive
example (p q : Prop) (h : p ↔ q) : ¬p ↔ ¬q := by
  constructor
  · -- case mp
    -- p q : Prop
    -- h : p ↔ q
    -- ⊢ ¬p → ¬q
    contrapose
    -- ⊢ ¬¬q → ¬¬p
    push_neg
    -- ⊢ q → p
    intro q'
    -- q' : q
    -- ⊢ p
    exact h.mpr q'
  
  · -- case mpr
    -- p q : Prop
    -- h : p ↔ q
    -- ⊢ ¬q → ¬p
    contrapose
    -- ⊢ ¬¬p → ¬¬q
    push_neg
    -- ⊢ p → q
    -- we do not need an intro; just use h.mp directly
    exact h.mp
```

In the previous chapter, we looked at proving distributivity of conjunction and disjunction. Lean has a lemma that we could have used called `and_or_left`. This lemma proves the equivalence: ```and_or_left {a b c : Prop} : a ∧ (b ∨ c) ↔ a ∧ b ∨ a ∧ c```.
```lean 
-- An alternative proof (and much shorter)
example (p q r : Prop) (h : p ∧ (q ∨ r)) : p ∧ q ∨ p ∧ r := by
  -- ⊢ p ∧ q ∨ p ∧ r
  apply and_or_left.mp
  -- ⊢ p ∧ (q ∨ r)
  assumption
```

You can also think of the forward implication as a function:
```lean
example (p q r : Prop) (h : p ∧ (q ∨ r)) : p ∧ q ∨ p ∧ r := by
  -- ⊢ p ∧ q ∨ p ∧ r
  have h' := and_or_left.mp h
  -- h' : p ∧ q ∨ p ∧ r
  -- ⊢ p ∧ (q ∨ r)
  exact h'
```

Of course, we can just use the lemma directly:
```lean
example (p q r : Prop) (h : p ∧ (q ∨ r)) : p ∧ q ∨ p ∧ r := by
  -- ⊢ p ∧ q ∨ p ∧ r
  exact and_or_left.mp h

```

Now try proving the reverse implication using `and_or_left`:
```lean
example (p q r : Prop) (h : p ∧ q ∨ p ∧ r) : p ∧ (q ∨ r) := by
  sorry
```

A **tautology** is an expression that's always true regardless of the truth values of its component propositions. Lean provides the powerful `tauto` tactic that can automatically prove any tautology or tautological equivalence. These should look familiar:

```lean
theorem double_negation (p : Prop) : ¬¬p ↔ p := by
  tauto

theorem negation_as_implication (p : Prop) : ¬p ↔ (p → False) := by
  tauto

theorem contrapositive_equivalence (p q : Prop) : (p → q) ↔ (¬q → ¬p) := by
  tauto

theorem implication_as_disjunction (p q : Prop) : (p → q) ↔ (¬p ∨ q) := by
  tauto

-- De Morgan's Laws as equivalences
theorem demorgan_and (p q : Prop) : ¬(p ∧ q) ↔ (¬p ∨ ¬q) := by
  tauto

theorem demorgan_or (p q : Prop) : ¬(p ∨ q) ↔ (¬p ∧ ¬q) := by
  tauto
```
The `tauto` tactic is remarkably powerful — it can automatically prove any statement that's true purely by logical structure. This includes:

- All tautologies (statements always true)
- All contradictions (statements always false, when the goal is to prove `False`)
- All logical equivalences between tautologically equivalent statements

Here are some examples of tautologies:

```lean
-- Distribution laws
theorem distribute_and_over_or (p q r : Prop) : 
  p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by tauto

theorem distribute_or_over_and (p q r : Prop) : 
  p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := by tauto

-- Complex logical relationships
theorem complex_tautology (p q r : Prop) : 
  ((p → q) ∧ (q → r)) → (p → r) := by tauto
```

**Practice Problems:**

Try proving these yourself using basic tactics (don't use `tauto`!):

```lean
example (p q : Prop) : ¬(p ∧ q) → (¬p ∨ ¬q) := by
  sorry

example (p q : Prop) : (p → q) → (¬q → ¬p) := by  
  sorry

example (p : Prop) : ¬¬p → p := by
  sorry

example (p q : Prop) : ¬(p ∨ q) → (¬p ∧ ¬q) := by
  sorry
```